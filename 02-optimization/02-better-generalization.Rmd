---
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
style_duo_accent(
  primary_color = "#133354",
  secondary_color = "#133354",
  inverse_header_color = "#FFFFFF"
)
```

```{r xaringan-tile-view, echo=FALSE}
xaringanExtra::use_tile_view()
xaringanExtra::use_animate_css()
```

```{r xaringan-panelset, echo=FALSE}
xaringanExtra::use_panelset()
```

```{r xaringan-tachyons, echo=FALSE}
xaringanExtra::use_tachyons()
```


background-image: url(img/city.jpg)
background-size: cover
class: inverse,  middle


## Optimization in Neural Networks
### Part 2: Better Generalization


fecha: `r Sys.Date()`

---

## Introduction

### Techniques to reduce overfitting and improve generalization
* How techniques that reduce model complexity have a **regularizing effect** resulting in less
overfitting and better generalization.
* How to add a **penalty to the loss function to encourage smaller model weights**.
*  How to add a **penalty to the loss function to encourage sparse internal representations**.
* How to add a **constraint to the model** to force small model weights and lower complexity
models.
* How to add **dropout weights** during training to decouple model layers.
* How to add **noise** to the training process to promote model robustness.
* How to use **early stopping** to halt model training at the right time.

---

# Fix Overfitting with Regularization


### Reduce Overfitting by Constraining Complexity

There are two ways to approach an overfit model:

* 1. Reduce overfitting by training the network on more examples.
* 2. Reduce overfitting by changing the complexity of the network.

A benefit of very deep neural networks is that their performance continues to improve as
they are fed larger and larger datasets. A model with a near-infinite number of examples will
eventually plateau in terms of what the capacity of the network is capable of learning. A model
can overfit a training dataset because it has sufficient capacity to do so. Reducing the capacity
of the model reduces the likelihood of the model overfitting the training dataset, to a point
where it no longer overfits. The capacity of a neural network model, **it’s complexity, is defined by both it’s structure in terms of nodes and layers and the parameters in terms of its weights.**

---

Therefore, we can reduce the complexity of a neural network to **reduce overfitting** in one of two
ways:

.bg-washed-yellow.b--gold.ba.bw2.br3.shadow-5.ph4.mt2[

* Change network complexity by changing the **network structure (number of weights)**.
* Change network complexity by changing the **network parameters (values of weights)**.

]

It is more common to focus on methods that constrain the size of the weights in a neural
network because a single network structure can be defined that is under-constrained, e.g. has a
much larger capacity than is required for the problem, and regularization can be used during
training to ensure that the model does not overfit.

Techniques that seek to reduce overfitting (reduce generalization error) by keeping
network weights small are referred to as **regularization methods.** More specifically, regularization
refers to a class of approaches that add additional information to transform an ill-posed problem
into a more stable well-posed problem.

---

## Regularization 

* Regularization methods are so widely used to reduce overfitting that the term regularization
may be used for any method that improves the generalization error of a neural network model.


.bg-lightest-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

Regularization is any modification we make to a learning algorithm that is intended
to reduce its generalization error but not its training error. Regularization is one of
the central concerns of the field of machine learning, rivaled in its importance only
by optimization.

.tr[
— Page 120, Deep Learning, 2016.
]]


---

## Regularization for Neural Networks

The simplest and perhaps most common regularization method is to add a penalty to the loss
function in proportion to the size of the weights in the model.

.bg-washed-yellow.b--gold.ba.bw2.br3.shadow-5.ph4.mt2[

**Weight Regularization: Penalize the model during training based on the magnitude of the weights.**

]


This will encourage the model to map the inputs to the outputs of the training dataset
in such a way that the weights of the model are kept small. This approach is called weight
regularization or weight decay and has proven very effective for decades for both simpler linear
models and neural networks.

#### Most common additional regularization methods.
* **Activity Regularization:** Penalize the model during training based on the magnitude
of the activations.
* **Weight Constraint:** Constrain the magnitude of weights to be within a range or below
a limit.
* **Dropout:** Probabilistically remove inputs during training.
* **Noise:** Add statistical noise to inputs during training.
* **Early Stopping:** Monitor model performance on a validation set and stop training when
performance degrades.

---



class: animated slideInRight fadeOutLeft, inverse, middle

background-image: url(img/diapo12.jpg)
background-size: cover


# Penalize Large Weights with Weigth Regularization


---


## Penalize Large Weights with Weigth Regularization

We will cover these topics:

.bg-lightest-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
* **Large weights in a neural network are a sign of a more complex network that has overfit
the training data.**
* **Penalizing a network based on the size of the network weights during training can reduce
overfitting.**
* **An L1 or L2 vector norm penalty can be added to the optimization of the network to
encourage smaller weights.**

]

---

## Problem with Large Weights

* The longer we train the network, the more specialized the weights will become to the training data, overfitting the training data. The weights will grow in size in order to handle the specifics of the examples seen in the training data. Large weights make the network unstable. Although the weights will be
specialized to the training dataset, minor variation or statistical noise on the expected inputs
will result in large differences in the output.

* Generally, we refer to this model as having a large variance and a small bias. That is, the
model is sensitive to the specific examples, the statistical noise, in the training dataset. 


.bg-washed-green.b--dark-green.ba.bw2.br3.shadow-5.ph4.mt2[
A model with large weights is more complex than a model with smaller weights. It is a sign of a network
that may be overly specialized to training data. In practice, **we prefer to choose the simpler models to solve a problem (e.g. Occam’s razor). We prefer models with smaller weights.**

]


---

Larger weights result in a larger penalty, in the form of a larger loss score. The optimization
algorithm will then push the model to have smaller weights, i.e. weights no larger than needed
to perform well on the training dataset. Smaller weights are considered more regular or less
specialized and as such, we refer to this penalty as weight regularization. When this approach of
penalizing model coefficients is used in other machine learning models such as linear regression
or logistic regression, it may be referred to as shrinkage, because the penalty encourages the
coefficients to shrink during the optimization process.

**The addition of a weight size penalty or weight regularization to a neural network has the effect of reducing generalization error and of allowing the model to pay less attention to less relevant input variables.**

--

### How to Penalize Large Weights

There are two parts to penalizing the model based on the size of the weights.


.bg-washed-yellow.b--gold.ba.bw2.br3.shadow-5.ph4.mt2[

1. The calculation of the size of the weights.
2. The amount of attention that the optimization process should pay to the penalty.

]

---

## Calculate the size of the weights 

Neural network weights are real-values that can be positive or negative, as such, simply adding
the weights is not sufficient. There are two main approaches used to calculate the size of the
weights, they are:

.bg-washed-yellow.b--gold.ba.bw2.br3.shadow-5.ph4.mt2[

* Calculate the sum of the absolute values of the weights, called the **L1 norm (or L1)**.
* Calculate the sum of the squared values of the weights, called the **L2 norm (or L2)**.

]


L1 encourages weights to 0.0 if possible, resulting in more sparse weights (weights with more
0.0 values). L2 offers more nuance, both penalizing larger weights more severely, but resulting
in less sparse weights. The use of L2 in linear and logistic regression is often referred to as
**Ridge Regression.** This is useful to know when trying to develop an intuition for the penalty or
examples of its usage.
In other academic communities, L2 regularization is also known as **ridge regression or Tikhonov regularization.**


---

### Weight decay

The weights may be considered a vector and the magnitude of a vector is called its norm,
from linear algebra. As such, penalizing the model based on the size of the weights is also
referred to as a weight or parameter norm penalty. **It is possible to include both L1 and L2 approaches to calculating the size of the weights as the penalty.** This is akin to the use of both
penalties used in the **Elastic Net algorithm** for linear and logistic regression. The L2 approach
is perhaps the most used and is traditionally referred to as weight decay in the field of neural
networks. It is called shrinkage in statistics, a name that encourages you to think of the impact
of the penalty on the model weights during the learning process.

.bg-washed-yellow.b--gold.ba.bw2.br3.shadow-5.ph4.mt2[
This particular choice of regularizer is known in the machine learning literature
as **weight decay** because in sequential learning algorithms, **it encourages weight values to decay towards zero**, unless supported by the data. In statistics, it provides
an example of a parameter shrinkage method because it shrinks parameter values
towards zero

.tr[
— Page 144-145, Pattern Recognition and Machine Learning, 2006.
]]


---

## Control Impact of the Penalty

* The calculated size of the weights is added to the loss objective function when training the
network. Rather than adding each weight to the penalty directly, they can be weighted using
a new hyperparameter called alpha (α) or sometimes lambda. This controls the amount of
attention that the learning process should pay to the penalty. Or put another way, the amount
to penalize the model based on the size of the weights. **The alpha hyperparameter has a value between 0.0 (no penalty) and 1.0 (full penalty).** 


* This hyperparameter controls the amount of bias in the model from 0.0, or low bias (high variance), to 1.0, or high bias (low variance). If the penalty is too strong, the model will underestimate the weights and underfit the problem. If the penalty is too weak, the model will be allowed to overfit the training data. The vector norm of the weights is often calculated per-layer, rather than across the entire network.
This allows more flexibility in the choice of the type of regularization used (e.g. L1 for inputs,
L2 elsewhere) and flexibility in the alpha value, although it is common to use the same alpha
value on each layer by default.


---


## Examples of Weight Regularization


* **.dark-red[Examples of MLP Weight Regularization]**

Weight regularization was borrowed from penalized regression models in statistics. The most
common type of regularization is L2, also called simply weight decay, with values often on a
logarithmic scale between 0 and 0.1, such as 0.1, 0.001, 0.0001, etc. Reasonable values of lambda *regularization hyperparameter* range between 0 and 0.1.

--

* **.dark-red[Examples of CNN Weight Regularization]**

Weight regularization does not seem widely used in CNN models, or if it is used, its use is not
widely reported. L2 weight regularization with very small regularization hyperparameters such
as (e.g. 0.0005 or 5 × 10−4 ) may be a good starting point. 

--

* **.dark-red[Examples of LSTM Weight Regularization]**

It is common to use weight regularization with LSTM models. An often used configuration is L2
(weight decay) and very small hyperparameters (e.g. 10−6 ). It is often not reported what weights
are regularized (input, recurrent, and/or bias), although one would assume that both input and
recurrent weights are regularized only.

---

## Tips for Using Weight Regularization

* **.dark-red[Use With All Network Types]**

Weight regularization is a generic approach. It can be used with most, perhaps all, types of
neural network models.

--

* **.dark-red[Standardize Input Data]**

It is generally good practice to update input variables to have the same scale. When input
variables have different scales, the scale of the weights of the network will, in turn, vary
accordingly. This introduces a problem when using weight regularization because the absolute
or squared values of the weights must be added for use in the penalty. This problem can be
addressed by either normalizing or standardizing input variables.

--

* **.dark-red[Use a Larger Network]**

It is common for larger networks (more layers or more nodes) to more easily overfit the training
data. When using weight regularization, it is possible to use larger networks with less risk of
overfitting. A good configuration strategy may be to start with larger networks and use weight
decay.


---

### Tips for Using Weight Regularization

* **.dark-red[Grid Search Parameters]**

It is common to use small values for the regularization hyperparameter that controls the
contribution of each weight to the penalty. Perhaps start by testing values on a log scale, such
as 0.1, 0.001, and 0.0001. Then use a grid search at the order of magnitude that shows the most
promise.

--

* **.dark-red[Use L1 + L2 Together]**

Rather than trying to choose between L1 and L2 penalties, use both. Modern and effective
linear regression methods such as the Elastic Net use both L1 and L2 penalties at the same
time and this can be a useful approach to try. This gives you both the nuance of L2 and the
sparsity encouraged by L1.

--

* **.dark-red[Use on a Trained Network]**

The use of weight regularization may allow more elaborate training schemes. For example, a
model may be fit on training data first without any regularization, then updated later with the
use of a weight penalty to reduce the size of the weights of the already well-performing model.

---

class: animated slideInRight fadeOutLeft, inverse, middle

background-image: url(img/diapo13.jpg)
background-size: cover

# Sparse Representations with Activity Regularization


---

## Sparse Representations with Activity Regularization

We will cover these topics:

.bg-lightest-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

* **Neural networks learn features from data and models, such as autoencoders and encoder-
decoder models, and explicitly seek effective learned representations.**
* **Similar to weights, large values in learned features, e.g. large activations, may indicate an
overfit model.**
* **The addition of penalties to the loss function that penalize a model in proportion to the
magnitude of the activations may result in more robust and generalized learned features.**

]